import os
import json
import re
import google.generativeai as genai
from google.generativeai.types import StopCandidateException # Import specific exception
from config import PROMPT_FILE_PATH, AI_MODEL_NAME
from utils import format_history_for_prompt
from logging_setup import logger # Import the logger

def _process_ai_response_json(ai_raw_text: str) -> tuple[str, str, str]:
    """
    X·ª≠ l√Ω chu·ªói ph·∫£n h·ªìi th√¥ t·ª´ AI, tr√≠ch xu·∫•t JSON, ki·ªÉm tra c·∫•u tr√∫c
    v√† chu·∫©n h√≥a ƒë∆∞·ªùng d·∫´n file.
    Raise ValueError n·∫øu ph·∫£n h·ªìi kh√¥ng h·ª£p l·ªá ho·∫∑c thi·∫øu tr∆∞·ªùng.
    """
    text = ai_raw_text.replace("\u00A0", " ").replace("\r", "")

    # ∆Øu ti√™n t√¨m kh·ªëi JSON ƒë∆∞·ª£c b·ªçc trong ```json
    match = re.search(r'```json\s*({.*?})\s*```', text, re.DOTALL)
    if not match:
        # N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m b·∫•t k·ª≥ ƒë·ªëi t∆∞·ª£ng JSON n√†o
        match = re.search(r'({.*?})', text, re.DOTALL)

    if not match:
        raise ValueError("AI kh√¥ng tr·∫£ v·ªÅ n·ªôi dung theo ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá.")

    json_string = match.group(1)
    try:
        data = json.loads(json_string)
    except json.JSONDecodeError:
        raise ValueError("AI tr·∫£ v·ªÅ chu·ªói kh√¥ng ph·∫£i l√† JSON h·ª£p l·ªá.")

    filepath = data.get("filepath")
    new_content = data.get("new_code")
    description = data.get("description")

    if not all([filepath, new_content, description]):
        missing_fields = []
        if not filepath: missing_fields.append("filepath")
        if not new_content: missing_fields.append("new_code")
        if not description: missing_fields.append("description")
        raise ValueError(f"JSON tr·∫£ v·ªÅ thi·∫øu c√°c tr∆∞·ªùng b·∫Øt bu·ªôc: {', '.join(missing_fields)}.")

    # ƒê·∫£m b·∫£o filepath b·∫Øt ƒë·∫ßu b·∫±ng 'app/' n·∫øu ch∆∞a c√≥
    if filepath and not filepath.startswith("app/"):
        filepath = "app/" + filepath
        
    return filepath, new_content, description

def invoke_ai_x(context: str, history_log: list):
    """
    Y√™u c·∫ßu AI X tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON ch·ª©a n·ªôi dung file m·ªõi v√† m√¥ t·∫£.
    Tr·∫£ v·ªÅ m·ªôt tuple: (filepath, new_content, description, failure_reason)
    """
    logger.info("ü§ñ [AI X] ƒêang k·∫øt n·ªëi Gemini, ƒë·ªçc l·ªãch s·ª≠ v√† t·∫°o ƒë·ªÅ xu·∫•t file m·ªõi...")
    with open(PROMPT_FILE_PATH, "r", encoding="utf-8") as f:
        prompt_template = f.read()
    
    # S·ª≠ d·ª•ng h√†m format_history_for_prompt t·ª´ module utils
    history_context = format_history_for_prompt(history_log)
    prompt_filled_history = prompt_template.replace("{history_context}", history_context)
    prompt = f"{prompt_filled_history}\n\n{context}"
    
    # Log the prompt details before sending (at DEBUG level)
    logger.debug(f"ü§ñ [AI X] G·ª≠i prompt t·ªõi Gemini. ƒê·ªô d√†i: {len(prompt)} k√Ω t·ª±. 1000 k√Ω t·ª± ƒë·∫ßu:\n{prompt[:1000]}...")
    
    model = genai.GenerativeModel(AI_MODEL_NAME)
    try:
        response = model.generate_content(prompt)
        
        # Log the raw response after receiving it (at DEBUG level)
        if response and hasattr(response, 'text'):
            logger.debug(f"ü§ñ [AI X] ƒê√£ nh·∫≠n ph·∫£n h·ªìi th√¥ t·ª´ Gemini (ƒë·ªô d√†i: {len(response.text)}): {response.text}")
        else:
            logger.debug(f"ü§ñ [AI X] Ph·∫£n h·ªìi t·ª´ Gemini kh√¥ng c√≥ thu·ªôc t√≠nh 'text' ho·∫∑c r·ªóng.")
            
        # B·ªï sung ki·ªÉm tra robust cho ph·∫£n h·ªìi API
        if not response.candidates:
            reason = "API Gemini tr·∫£ v·ªÅ kh√¥ng c√≥ ·ª©ng c·ª≠ vi√™n (candidate). C√≥ th·ªÉ do b·ªã ch·∫∑n n·ªôi dung ho·∫∑c kh√¥ng t·∫°o ƒë∆∞·ª£c ph·∫£n h·ªìi." 
            logger.error(f"‚ùå L·ªói khi g·ªçi Gemini API cho AI X: {reason}")
            return None, None, None, reason
        
        if not response.text.strip():
            reason = "API Gemini tr·∫£ v·ªÅ ph·∫£n h·ªìi r·ªóng ho·∫∑c ch·ªâ ch·ª©a kho·∫£ng tr·∫Øng sau khi t·∫°o n·ªôi dung." 
            logger.error(f"‚ùå L·ªói khi g·ªçi Gemini API cho AI X: {reason}")
            return None, None, None, reason
            
        try:
            filepath, new_content, description = _process_ai_response_json(response.text)
            logger.info("ü§ñ [AI X] ƒê√£ nh·∫≠n ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t JSON h·ª£p l·ªá.")
            return filepath, new_content, description, None
        except ValueError as ve:
            # L·ªói t·ª´ h√†m x·ª≠ l√Ω JSON
            return None, None, None, str(ve)

    except StopCandidateException as e:
        reason = f"ƒê·ªÅ xu·∫•t b·ªã ch·∫∑n do ch√≠nh s√°ch an to√†n ho·∫∑c l√Ω do kh√°c: {e}"
        logger.error(f"‚ùå L·ªói khi g·ªçi Gemini API cho AI X (StopCandidateException): {reason}", exc_info=True)
        return None, None, None, reason
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi g·ªçi Gemini API cho AI X: {e}", exc_info=True)
        return None, None, None, str(e)
