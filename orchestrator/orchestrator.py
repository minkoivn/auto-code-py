# orchestrator/orchestrator.py
import os
import subprocess
import json
import re
import time
import py_compile
from dotenv import load_dotenv
import google.generativeai as genai

# --- CÃC HÃ€M TIá»†N ÃCH VÃ€ Cáº¤U HÃŒNH ---

LOG_FILE_PATH = "orchestrator/evolution_log.json"

def setup():
    """Táº£i biáº¿n mÃ´i trÆ°á»ng vÃ  cáº¥u hÃ¬nh API Key cho Gemini."""
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY not found. Please set it in the .env file.")
    genai.configure(api_key=api_key)
    print("âœ… ÄÃ£ cáº¥u hÃ¬nh Gemini API Key.")

def get_source_code_context():
    """Äá»c mÃ£ nguá»“n thÆ° má»¥c 'app' Ä‘á»ƒ lÃ m bá»‘i cáº£nh."""
    context = ""
    for root, _, files in os.walk("app"):
        for file in files:
            if file.endswith(".py"):
                filepath = os.path.join(root, file)
                context += f"--- File: {filepath} ---\n"
                with open(filepath, "r", encoding="utf-8") as f:
                    context += f.read()
                context += "\n\n"
    return context

# --- CÃC HÃ€M TÆ¯Æ NG TÃC Vá»šI AI VÃ€ LOG ---

def format_history_for_prompt(history_log: list, num_entries=10) -> str:
    """Äá»‹nh dáº¡ng cÃ¡c má»¥c log gáº§n Ä‘Ã¢y nháº¥t Ä‘á»ƒ Ä‘Æ°a vÃ o prompt."""
    if not history_log:
        return "ChÆ°a cÃ³ lá»‹ch sá»­."
    
    recent_history = history_log[-num_entries:]
    formatted_history = ""
    for entry in recent_history:
        formatted_history += f"- Láº§n {entry['iteration']}: Tráº¡ng thÃ¡i = {entry['status']}. LÃ½ do = {entry['reason']}\n"
    return formatted_history

def invoke_ai_x(context: str, history_log: list):
    """
    YÃªu cáº§u AI X tráº£ vá» ná»™i dung file má»›i vÃ  mÃ´ táº£ thay Ä‘á»•i.
    Tráº£ vá» má»™t tuple: (filepath, new_content, description, failure_reason)
    """
    print("ğŸ¤– [AI X] Äang káº¿t ná»‘i Gemini, Ä‘á»c lá»‹ch sá»­ vÃ  táº¡o Ä‘á» xuáº¥t file má»›i...")
    with open("orchestrator/prompts/x_prompt.txt", "r", encoding="utf-8") as f:
        prompt_template = f.read()
    
    history_context = format_history_for_prompt(history_log)
    prompt_filled_history = prompt_template.replace("{history_context}", history_context)
    prompt = f"{prompt_filled_history}\n\n{context}"
    
    # Sá»­a tÃªn model náº¿u cáº§n, vÃ­ dá»¥ 'gemini-2.5-flash'
    model = genai.GenerativeModel('gemini-2.5-flash') 
    try:
        response = model.generate_content(prompt)
        text = response.text.replace("\u00A0", " ").replace("\r", "")
        
        # Cáº­p nháº­t regex Ä‘á»ƒ trÃ­ch xuáº¥t cáº£ description
        match = re.search(
            r'<change>\s*<description>(.*?)</description>\s*<new_code filepath="([^"]+)">\s*(.*?)\s*</new_code>\s*</change>',
            text,
            re.DOTALL
        )
        
        if match:
            description = match.group(1).strip()
            filepath = match.group(2).strip()
            new_content = match.group(3).strip()
            
            if not os.path.exists(filepath):
                return None, None, None, f"AI Ä‘á» xuáº¥t sá»­a file khÃ´ng tá»“n táº¡i: {filepath}"
            
            with open(filepath, 'r', encoding='utf-8') as f:
                original_content = f.read()
            if original_content == new_content:
                return None, None, None, "Ná»™i dung AI Ä‘á» xuáº¥t giá»‘ng há»‡t file gá»‘c."

            print("ğŸ¤– [AI X] ÄÃ£ nháº­n Ä‘Æ°á»£c Ä‘á» xuáº¥t ná»™i dung file má»›i vÃ  mÃ´ táº£.")
            return filepath, new_content, description, None
        else:
            return None, None, None, "AI khÃ´ng tráº£ vá» ná»™i dung theo Ä‘á»‹nh dáº¡ng <change>..."

    except Exception as e:
        print(f"âŒ Lá»—i khi gá»i Gemini API cho AI X: {e}")
        return None, None, None, str(e)


# --- HÃ€M THá»°C THI KIáº¾N TRÃšC Má»šI ---

def validate_and_commit_changes(filepath: str, new_content: str, description: str):
    """
    Kiá»ƒm tra cÃº phÃ¡p, náº¿u há»£p lá»‡ thÃ¬ ghi Ä‘Ã¨ vÃ  commit vá»›i mÃ´ táº£ Ä‘Æ°á»£c cung cáº¥p.
    Tráº£ vá» má»™t tuple (status, final_reason).
    """
    print(f"ğŸš€ [Z] Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh thá»±c thi cho file: {filepath}")
    temp_filepath = filepath + ".tmp"
    try:
        with open(temp_filepath, "w", encoding="utf-8") as f:
            f.write(new_content)
        
        py_compile.compile(temp_filepath, doraise=True)
        print("âœ… [VALIDATOR] MÃ£ nguá»“n má»›i há»£p lá»‡.")

        os.replace(temp_filepath, filepath)
        print(f"ğŸ“ ÄÃ£ ghi Ä‘Ã¨ thÃ nh cÃ´ng file: {filepath}")
        
        subprocess.run(["git", "add", filepath], check=True)
        # Sá»­ dá»¥ng description tá»« AI Ä‘á»ƒ táº¡o commit message
        commit_message = f"feat(AI): {description}"
        subprocess.run(["git", "commit", "-m", commit_message], check=True)
        print(f"ğŸš€ [Z] ÄÃ£ táº¡o commit má»›i: '{commit_message}'")
        
        return "COMMITTED", description

    except py_compile.PyCompileError as e:
        error_reason = f"Lá»—i cÃº phÃ¡p trong Ä‘á» xuáº¥t má»›i: {e}"
        print(f"âŒ [VALIDATOR] {error_reason}")
        return "REJECTED_VALIDATION_FAILED", error_reason
    except Exception as e:
        error_reason = f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh trong quÃ¡ trÃ¬nh thá»±c thi: {e}"
        print(f"âŒ [Z] {error_reason}")
        return "EXECUTION_FAILED", error_reason
    finally:
        if os.path.exists(temp_filepath):
            os.remove(temp_filepath)


# --- LUá»’NG CHÃNH ÄÆ¯á»¢C Cáº¬P NHáº¬T ---

def main():
    """HÃ m chÃ­nh chá»©a vÃ²ng láº·p vÃ  quáº£n lÃ½ lá»‹ch sá»­ bá»n vá»¯ng."""
    setup()
    
    history_log = []
    if os.path.exists(LOG_FILE_PATH):
        try:
            with open(LOG_FILE_PATH, "r", encoding="utf-8") as f:
                history_log = json.load(f)
            print(f"ğŸ“š ÄÃ£ táº£i {len(history_log)} má»¥c tá»« lá»‹ch sá»­.")
        except json.JSONDecodeError:
            print(f"âš ï¸ File log {LOG_FILE_PATH} bá»‹ lá»—i, báº¯t Ä‘áº§u lá»‹ch sá»­ má»›i.")
            history_log = []

    iteration_count = len(history_log)

    try:
        while True:
            iteration_count += 1
            print("\n" + "="*50)
            print(f"ğŸ¬ Báº®T Äáº¦U CHU TRÃŒNH TIáº¾N HÃ“A Láº¦N THá»¨ {iteration_count}")
            print("="*50)
            
            log_entry = { "iteration": iteration_count, "status": "", "reason": "" }
            source_context = get_source_code_context()
            filepath, new_content, description, failure_reason = invoke_ai_x(source_context, history_log)
            
            if filepath and new_content and description:
                status, final_reason = validate_and_commit_changes(filepath, new_content, description)
                log_entry["status"] = status
                log_entry["reason"] = final_reason
            else:
                print(f"âŒ AI X khÃ´ng táº¡o ra Ä‘á» xuáº¥t há»£p lá»‡. LÃ½ do: {failure_reason}")
                log_entry["status"] = "NO_PROPOSAL"
                log_entry["reason"] = failure_reason
            
            history_log.append(log_entry)
            with open(LOG_FILE_PATH, "w", encoding="utf-8") as f:
                json.dump(history_log, f, indent=4, ensure_ascii=False)
            print(f"ğŸ“ ÄÃ£ cáº­p nháº­t log vÃ o file: {LOG_FILE_PATH}")
            
            print(f"â³ Táº¡m nghá»‰ 15 giÃ¢y...")
            time.sleep(15)

    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ÄÃ£ nháº­n tÃ­n hiá»‡u dá»«ng.")
    except Exception as e:
        print(f"â›” ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")

if __name__ == "__main__":
    main()
